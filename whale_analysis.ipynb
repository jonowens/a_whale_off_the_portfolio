{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  A Whale off the Port(folio)\n",
    "\n",
    " In this assignment, you'll get to use what you've learned this week to evaluate the performance among various algorithmic, hedge, and mutual fund portfolios and compare them against the S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this section, you will need to read the CSV files into DataFrames and perform any necessary data cleaning steps. After cleaning, combine all DataFrames into a single DataFrame.\n",
    "\n",
    "Files:\n",
    "1. whale_returns.csv\n",
    "2. algo_returns.csv\n",
    "3. sp500_history.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whale Returns\n",
    "\n",
    "Read the Whale Portfolio daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading whale returns\n",
    "whale_returns_csv = Path(\"Resources/whale_returns.csv\")\n",
    "whale_returns = pd.read_csv(whale_returns_csv, index_col='Date', infer_datetime_format=True, parse_dates=True)\n",
    "whale_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "whale_returns.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "whale_returns = whale_returns.dropna()\n",
    "whale_returns.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmic Daily Returns\n",
    "\n",
    "Read the algorithmic daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading algorithmic returns\n",
    "algo_returns_csv = Path(\"Resources/algo_returns.csv\")\n",
    "algo_returns = pd.read_csv(algo_returns_csv, index_col='Date', infer_datetime_format=True, parse_dates=True)\n",
    "algo_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "algo_returns.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "algo_returns = algo_returns.dropna()\n",
    "algo_returns.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 Returns\n",
    "\n",
    "Read the S&P500 Historic Closing Prices and create a new daily returns DataFrame from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading S&P 500 Closing Prices\n",
    "sp500_history_csv = Path(\"Resources/sp500_history.csv\")\n",
    "sp500_history = pd.read_csv(sp500_history_csv, index_col='Date', infer_datetime_format=True, parse_dates=True)\n",
    "sp500_history.sort_index(inplace=True)\n",
    "sp500_history.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Data Types\n",
    "sp500_history.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Data Types\n",
    "sp500_history[\"Close\"] = sp500_history[\"Close\"].str.replace(\"$\",\"\")\n",
    "sp500_history[\"Close\"] = sp500_history[\"Close\"].astype(\"float\")\n",
    "sp500_history.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Returns\n",
    "sp500_returns = sp500_history.pct_change()\n",
    "sp500_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "sp500_returns.dropna().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Column\n",
    "sp500_returns.rename(columns={\"Close\": \"S&P 500\"}, inplace=True)\n",
    "sp500_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Whale, Algorithmic, and S&P 500 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_returns = pd.concat([whale_returns, algo_returns, sp500_returns], axis=\"columns\", join=\"inner\")\n",
    "combined_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Analysis\n",
    "\n",
    "In this section, you will calculate and visualize performance and risk metrics for the portfolios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "Calculate and Plot the daily returns and cumulative returns. Does any portfolio outperform the S&P 500? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily returns\n",
    "combined_returns.plot(title=\"Daily Returns\", figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "cumulative_returns = (1 + combined_returns).cumprod()\n",
    "cumulative_returns.plot(title=\"Cumulative Returns\", figsize=(20,10))"
   ]
  },
  {
   "source": [
    "### *Algo 1 out performed the S&P 500.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk\n",
    "\n",
    "Determine the _risk_ of each portfolio:\n",
    "\n",
    "1. Create a box plot for each portfolio. \n",
    "2. Calculate the standard deviation for all portfolios\n",
    "4. Determine which portfolios are riskier than the S&P 500\n",
    "5. Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot to visually show risk\n",
    "combined_returns.boxplot(figsize=(20,10)).set_title(\"Portfolio Risk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Standard Deviations\n",
    "# Calculate the standard deviation for each portfolio. \n",
    "# Which portfolios are riskier than the S&P 500?\n",
    "combined_daily_std = combined_returns.std()\n",
    "combined_daily_std"
   ]
  },
  {
   "source": [
    "### *Tiger Global Management LLC and Berkshire Hathaway Inc have greater risk compared to the S&P 500."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine which portfolios are riskier than the S&P 500\n",
    "index_num = 0\n",
    "for portfolio in combined_daily_std:\n",
    "    if portfolio > combined_daily_std[\"S&P 500\"]:\n",
    "        true_false = \"True\"\n",
    "        print(f\"{combined_daily_std.index[index_num]:<30}{true_false:>6}\")\n",
    "    else:\n",
    "        true_false = \"False\"\n",
    "        print(f\"{combined_daily_std.index[index_num]:<30}{true_false:>6}\")\n",
    "    index_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized standard deviation (252 trading days)\n",
    "annualized_combined_std = combined_daily_std * np.sqrt(252)\n",
    "annualized_combined_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics\n",
    "\n",
    "Risk changes over time. Analyze the rolling statistics for Risk and Beta. \n",
    "\n",
    "1. Plot the rolling standard deviation of the various portfolios along with the rolling standard deviation of the S&P 500 (consider a 21 day window). Does the risk increase for each of the portfolios at the same time risk increases in the S&P?\n",
    "2. Construct a correlation table for the algorithmic, whale, and S&P 500 returns. Which returns most closely mimic the S&P?\n",
    "3. Choose one portfolio and plot a rolling beta between that portfolio's returns and S&P 500 returns. Does the portfolio seem sensitive to movements in the S&P 500?\n",
    "4. An alternative way to calculate a rolling window is to take the exponentially weighted moving average. This is like a moving window average, but it assigns greater importance to more recent observations. Try calculating the ewm with a 21 day half-life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the rolling standard deviation for\n",
    "# the S&P 500 and whale portfolios using a 21 trading day window\n",
    "combined_returns.rolling(window=21).std().plot(figsize=(20,10), title=\"21 Day Rolling Standard Deviation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a correlation table\n",
    "correlation = combined_returns.corr()\n",
    "sns.heatmap(correlation, vmin=0, vmax=1, cmap=\"YlGn\", annot=True).set_title(\"Correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate Beta for a single portfolio compared to the total market (S&P 500)\n",
    "# (Your graph may differ, dependent upon which portfolio you are comparing)\n",
    "rolling_covariance = combined_returns['BERKSHIRE HATHAWAY INC'].rolling(window=21).cov(combined_returns['S&P 500'])\n",
    "rolling_variance = combined_returns['S&P 500'].rolling(window=21).var()\n",
    "rolling_beta = rolling_covariance / rolling_variance\n",
    "rolling_beta.plot(figsize=(20,10), title=\"Berkshire Hathaway Inc Beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate a rolling window using the exponentially weighted moving average.\n",
    "expo_rolling_window = combined_returns.ewm(halflife=21).mean()\n",
    "expo_rolling_window.plot(figsize=(20,10), title=\"Exponential Weighted Average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "source": [
    "## Sharpe Ratios\n",
    "In reality, investment managers and their institutional investors look at the ratio of return-to-risk, and not just returns alone. (After all, if you could invest in one of two portfolios, each offered the same 10% return, yet one offered lower risk, you'd take that one, right?)\n",
    "\n",
    "1. Using the daily returns, calculate and visualize the Sharpe ratios using a bar plot.\n",
    "2. Determine whether the algorithmic strategies outperform both the market (S&P 500) and the whales portfolios."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate annualized Sharpe Ratios\n",
    "sharpe_ratios = (combined_returns.mean() * 252) / (combined_returns.std() * np.sqrt(252))\n",
    "sharpe_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "sharpe_ratios.plot(kind = 'bar', title = 'Sharpe Ratios')"
   ]
  },
  {
   "source": [
    "On the basis of this performance metric, do our algo strategies outperform both 'the market' and the whales? Type your answer here:\n",
    "\n",
    "### *Based on this performance metric, Algo 1 outperforms both 'the market' and the whales, while Algo 2 does not outperform them.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Returns\n",
    "\n",
    "In this section, you will build your own portfolio of stocks, calculate the returns, and compare the results to the Whale Portfolios and the S&P 500. \n",
    "\n",
    "1. Visit [Google Sheets](https://docs.google.com/spreadsheets/) and use the in-built Google Finance function to choose 3-5 stocks for your own portfolio.\n",
    "2. Download the data as CSV files and calculate the portfolio returns.\n",
    "3. Calculate the returns for each stock.\n",
    "4. Using those returns, calculate the weighted returns for your entire portfolio assuming an equal number of shares for each stock.\n",
    "5. Add your portfolio returns to the DataFrame with the other portfolios and rerun the analysis. How does your portfolio fair?\n",
    "\n",
    "\n",
    "## Your analysis should include the following:\n",
    "\n",
    "- Using all portfolios:\n",
    " - The annualized standard deviation (252 trading days) for all portfolios.\n",
    " - The plotted rolling standard deviation using a 21 trading day window for all portfolios.\n",
    " - The calculated annualized Sharpe Ratios and the accompanying bar plot visualization.\n",
    " - A correlation table.\n",
    "- Using your custom portfolio and one other of your choosing:\n",
    " - The plotted beta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first stock\n",
    "chrw_csv = Path(\"Resources/CHRW.csv\")\n",
    "chrw_data = pd.read_csv(chrw_csv, index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
    "chrw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the second stock\n",
    "xom_csv = Path(\"Resources/XOM.csv\")\n",
    "xom_data = pd.read_csv(xom_csv, index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
    "xom_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the third stock\n",
    "zts_csv = Path(\"Resources/zts.csv\")\n",
    "zts_data = pd.read_csv(zts_csv, index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
    "zts_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all stocks into a single DataFrame\n",
    "combined_data = pd.concat([chrw_data, xom_data, zts_data], axis=\"columns\", join=\"inner\")\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot so that each column of prices represents a unique symbol\n",
    "combined_data.columns = ['CHRW', 'XOM', 'ZTS']\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nulls\n",
    "daily_returns = combined_data.pct_change()\n",
    "daily_returns = daily_returns.dropna()\n",
    "daily_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted portfolio returns\n",
    "weights = [1/3, 1/3, 1/3]\n",
    "portfolio_weighted_returns = daily_returns.dot(weights)\n",
    "portfolio_weighted_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join your portfolio returns to the DataFrame that contains all of the portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add your \"Custom\" portfolio to the larger dataframe of fund returns\n",
    "all_portfolios_returns = pd.concat([combined_returns, portfolio_weighted_returns], axis=\"columns\", join=\"inner\")\n",
    "all_portfolios_returns.rename(columns={0: \"Custom\"}, inplace=True)\n",
    "all_portfolios_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only compare dates where return data exists for all the stocks (drop NaNs)\n",
    "all_portfolios_returns.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run the performance and risk analysis with your portfolio to see how it compares to the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk\n",
    "portfolios_risk = all_portfolios_returns.std() * np.sqrt(252)\n",
    "portfolios_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling\n",
    "all_portfolios_returns.rolling(window=21).std().plot(figsize=(20,10), title=\"21 Day Rolling Standard Deviation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annualized Sharpe Ratios\n",
    "all_annualized_sharpe_ratios = (all_portfolios_returns.mean() * 252) / (portfolios_risk)\n",
    "all_annualized_sharpe_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "all_annualized_sharpe_ratios.plot(kind='bar', figsize=(15,5), title='Annualized Sharpe Ratios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation analysis\n",
    "all_correlations = all_portfolios_returns.corr()\n",
    "sns.heatmap(all_correlations, vmin=0, vmax=0.9, cmap=\"YlGn\", annot=True).set_title(\"Portfolios Correlations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta\n",
    "custom_rolling_covariance = all_portfolios_returns['Custom'].rolling(window=21).cov(all_portfolios_returns['S&P 500'])\n",
    "custom_rolling_variance = all_portfolios_returns['S&P 500'].rolling(window=21).var()\n",
    "custom_rolling_beta = custom_rolling_covariance / custom_rolling_variance\n",
    "custom_rolling_beta.plot(figsize=(20,10), title=\"Beta for Custom Portfolio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}